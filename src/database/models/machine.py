import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
  


 
st.title("Resultados do Machine Learning")

st.markdown("##### üß™ O processo de otimiza√ß√£o de modelos de machine learning foi conclu√≠do com sucesso. A seguir, apresentamos os resultados dos modelos otimizados, incluindo m√©tricas de avalia√ß√£o e tempos de treinamento.")

st.markdown("##### üß† Nosso grande desafio foi identificar corretamente a classe de sementes de trigo com base em atributos f√≠sicos como √°rea, per√≠metro e compacidade. Como as classes s√£o balanceadas e os dados possuem caracter√≠sticas n√£o-lineares, modelos que exploram essa complexidade naturalmente se destacam.")     

pasta_resultados = "../fiap_sprint3_reply/src/machine_learning"

resultado_caminho = os.path.join(pasta_resultados, "resultados_modelos_otimizados.csv")
tempo_caminho = os.path.join(pasta_resultados, "tempos_modelos_otimizados.csv")

if not os.path.exists(resultado_caminho) or not os.path.exists(tempo_caminho):
    st.error("Arquivos de resultados ou tempos n√£o encontrados.")
    
else:
    # Carrega o Dataset de resultados
    df_resultados = pd.read_csv(resultado_caminho)
    df_tempos = pd.read_csv(tempo_caminho)
    
    # Pega o numero de modelos para saber quantas cores gerar
    num_modelos = len(df_resultados)
    
    cores_gradiente = plt.colormaps['viridis'](np.linspace(0.2, 0.8, num_modelos))


    st.header("Tabela de M√©tricas de Avalia√ß√£o")
    st.dataframe(df_resultados.set_index('Modelo'))

    st.header("Gr√°ficos de Compara√ß√£o")

    # Gr√°fico de Acur√°cia
    st.subheader("Acur√°cia dos Modelos")
    fig_acuracia, ax_acuracia = plt.subplots(figsize=(8, 4))
    ax_acuracia.barh(df_resultados['Modelo'], df_resultados['Accuracy'], color=cores_gradiente)
    ax_acuracia.set_xlabel('Acur√°cia')
    ax_acuracia.set_title('Acur√°cia por Modelo Otimizado')
    ax_acuracia.set_xlim(0, 1) 
    st.pyplot(fig_acuracia)

    # Gr√°fico de F1-Score
    st.subheader("F1-Score dos Modelos")
    fig_f1, ax_f1 = plt.subplots(figsize=(6, 4))
    ax_f1.barh(df_resultados['Modelo'], df_resultados['F1 Score'], color=cores_gradiente)
    ax_f1.set_xlabel('F1 Score')
    ax_f1.set_title('F1 Score por Modelo Otimizado')
    ax_f1.set_xlim(0, 1)
    st.pyplot(fig_f1)

    # Gr√°fico de Tempo de Treinamento
    st.subheader("Tempo de Treinamento")
    fig_tempo, ax_tempo = plt.subplots(figsize=(6, 4))
    ax_tempo.bar(df_tempos['Modelo'], df_tempos['Tempo Treinamento (s)'], color=cores_gradiente)
    ax_tempo.set_ylabel('Tempo (s)')
    ax_tempo.set_title('Tempo de Treinamento por Modelo Otimizado')
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    
    st.pyplot(fig_tempo)
    
    st.header("üîç Resumo da An√°lise dos Resultados")
    
    st.markdown("###### - Modelos lineares como **Logistic Regression** e **LDA** alcan√ßam desempenho razo√°vel, mas n√£o atingem a performance dos ensembles, por serem limitados a rela√ß√µes lineares entre caracter√≠sticas e classe.")
            
    st.markdown("###### - Random Forest e outras t√©cnicas de ensemble t√™m maior capacidade de modelar intera√ß√µes complexas e reduzir o overfitting, por isso figuram entre os melhores.")
            
    st.markdown("###### - A melhora significativa do SVM sigmoid sugere que esse kernel espec√≠fico √© particularmente eficaz para nossos dados, capturando n√£o linearidades que kernels lineares n√£o conseguem.")
    
    
    st.header("üéØ Conclus√£o")
    
    st.markdown("### Modelos simples mant√™m utilidade para cen√°rios que priorizam interpretabilidade e rapidez. Para a tarefa de classifica√ß√£o de sementes, recomenda-se priorizar modelos como Random Forest e SVM otimizados, avaliando a rela√ß√£o custo-benef√≠cio entre ganho de performance e tempo computacional.")
    