import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
  


def _machine_learning_results():
    
    """
    Fun√ß√£o para exibir os resultados do processo de machine learning.
    """
    # Verifica se a pasta de resultados existe
    pasta_resultados = os.path.join(os.path.dirname(__file__), "..", "machine_learning")
    
    
    if not os.path.exists(pasta_resultados):
        st.error("Pasta de resultados n√£o encontrada.")
        return 
    st.title("Resultados do Machine Learning")

    st.markdown("##### üß™ O processo de otimiza√ß√£o de modelos de machine learning foi conclu√≠do com sucesso. A seguir, apresentamos os resultados dos modelos otimizados, incluindo m√©tricas de avalia√ß√£o e tempos de treinamento.")

    st.markdown("##### üß† Nosso grande desafio foi identificar corretamente a classe de sementes de trigo com base em atributos f√≠sicos como √°rea, per√≠metro e compacidade. Como as classes s√£o balanceadas e os dados possuem caracter√≠sticas n√£o-lineares, modelos que exploram essa complexidade naturalmente se destacam.")     

    
    resultado_caminho = os.path.join(pasta_resultados, "resultados_modelos_otimizados.csv")
    tempo_caminho = os.path.join(pasta_resultados, "tempos_modelos_otimizados.csv")

    if not os.path.exists(resultado_caminho) or not os.path.exists(tempo_caminho):
        st.error("Arquivos de resultados ou tempos n√£o encontrados.")
        
    else:
        # Carrega o Dataset de resultados
        df_resultados = pd.read_csv(resultado_caminho)
        df_tempos = pd.read_csv(tempo_caminho)
        
        # Pega o numero de modelos para saber quantas cores gerar
        num_modelos = len(df_resultados)
        
        cores_gradiente = plt.colormaps['viridis'](np.linspace(0.2, 0.8, num_modelos))


        st.header("Tabela de M√©tricas de Avalia√ß√£o")
        st.dataframe(df_resultados.set_index('Modelo'))

        st.header("Gr√°ficos de Compara√ß√£o")

        # Gr√°fico de Acur√°cia
        st.subheader("Acur√°cia dos Modelos")
        fig_acuracia, ax_acuracia = plt.subplots(figsize=(8, 4))
        ax_acuracia.barh(df_resultados['Modelo'], df_resultados['Accuracy'], color=cores_gradiente)
        ax_acuracia.set_xlabel('Acur√°cia')
        ax_acuracia.set_title('Acur√°cia por Modelo Otimizado')
        ax_acuracia.set_xlim(0, 1) 
        st.pyplot(fig_acuracia)
        
        st.text('''
            Modelos menos precisos:
        - Decision Tree (d3 e dNone) aparecem no in√≠cio, com acur√°cia um pouco inferior aos demais (cerca de 0.82 - 0.84). 
        - Esses modelos tendem a ser mais simples e menos robustos, o que explica a menor performance.
        
            Melhor desempenho:
        - MLP (rede neural com 100 neur√¥nios na camada escondida) apresenta a maior acur√°cia (~0.93).
        - Isso sugere que o problema em quest√£o se beneficia de maior capacidade de modelagem n√£o-linear.
        
        ''')

        # Gr√°fico de F1-Score
        st.subheader("F1-Score dos Modelos")
        fig_f1, ax_f1 = plt.subplots(figsize=(6, 4))
        ax_f1.barh(df_resultados['Modelo'], df_resultados['F1 Score'], color=cores_gradiente)
        ax_f1.set_xlabel('F1 Score')
        ax_f1.set_title('F1 Score por Modelo Otimizado')
        ax_f1.set_xlim(0, 1)
        st.pyplot(fig_f1)

        st.text('''
            Modelos com menor F1 Score:
        - Decision Tree (d3 e dNone) est√£o no final da lista novamente, com desempenho inferior (F1 pr√≥ximo de 0.82 - 0.84).
        - Isso refor√ßa que √°rvores de decis√£o simples n√£o conseguem capturar bem a complexidade do problema.

            Melhor desempenho:
        - MLP (rede neural com 100 neur√¥nios na camada escondida) apresenta a maior acur√°cia (~0.93).
        - Isso sugere que o problema em quest√£o se beneficia de maior capacidade de modelagem n√£o-linear.
        ''')
        # Gr√°fico de Tempo de Treinamento
        st.subheader("Tempo de Treinamento")
        fig_tempo, ax_tempo = plt.subplots(figsize=(6, 4))
        ax_tempo.bar(df_tempos['Modelo'], df_tempos['Tempo Treinamento (s)'], color=cores_gradiente)
        ax_tempo.set_ylabel('Tempo (s)')
        ax_tempo.set_title('Tempo de Treinamento por Modelo Otimizado')
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        
        
        st.pyplot(fig_tempo)
        
        st.text('''
            Modelos extremamente r√°pidos:
        - Logistic Regression (86), Decision Tree (d3, dNone), Naive Bayes, QDA, KNN (5 e 7) tiveram tempos de treinamento praticamente desprez√≠veis (menos de 2 segundos).
        - S√£o modelos leves, adequados quando velocidade √© importante.)
        
            Modelos muito pesados:
        - GradBoost 200 (~35s) e principalmente MLP (100) (~110s) foram os mais lentos.
        - O custo da rede neural foi muito superior ao dos demais, confirmando o trade-off: maior acur√°cia/F1, mas com alto tempo de treinamento.
        
                ''')
        
        
        st.header("üîç Resumo da An√°lise dos Resultados")
        
        st.markdown("###### - Modelos lineares como **Logistic Regression** e **LDA** alcan√ßam desempenho razo√°vel, mas n√£o atingem a performance dos ensembles, por serem limitados a rela√ß√µes lineares entre caracter√≠sticas e classe.")
                
        st.markdown("###### - Random Forest e outras t√©cnicas de ensemble t√™m maior capacidade de modelar intera√ß√µes complexas e reduzir o overfitting, por isso figuram entre os melhores.")
                
        st.markdown("###### - A melhora significativa do SVM sigmoid sugere que esse kernel espec√≠fico √© particularmente eficaz para nossos dados, capturando n√£o linearidades que kernels lineares n√£o conseguem.")
        
        
        st.header("üéØ Conclus√£o")
        
        st.markdown("### Modelos simples mant√™m utilidade para cen√°rios que priorizam interpretabilidade e rapidez. Para a tarefa de classifica√ß√£o de sementes, recomenda-se priorizar modelos como Random Forest e SVM otimizados, avaliando a rela√ß√£o custo-benef√≠cio entre ganho de performance e tempo computacional.")
    